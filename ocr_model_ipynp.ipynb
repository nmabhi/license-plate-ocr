{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ocr_model.ipynp",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHgAK5QcOQJT"
      },
      "source": [
        "Mount google drive\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJKeyTUqLKOk",
        "outputId": "43c09847-bf6b-4e5b-88c3-702182ccc44f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%cd /content/drive/MyDrive/license_plate_ocr/\n",
        "!ls"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/license_plate_ocr\n",
            "5cnn_model.h5\t       8cnn_128lstm_model.h5  hdr.zip\t  output.csv\n",
            "7cnn_128lstm_model.h5  dataset.csv\t      normal\t  Untitled.ipynb\n",
            "7cnn_model.h5\t       hdr\t\t      normal.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhaOgSgzRXFs"
      },
      "source": [
        "Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbp02BEaMgjs"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import cv2\n",
        "\n",
        "from pathlib import Path\n",
        "from collections import Counter\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZOBHL-HScKK"
      },
      "source": [
        "Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdLD6xMhSeLg"
      },
      "source": [
        "dataset = pd.read_csv(\"dataset.csv\",names=[\"images\",\"labels\"])\n",
        "dataset[\"images\"] = dataset[\"images\"].apply(lambda s:\"hdr/\"+s if \"crop_h\" in s else \"normal/\"+s)\n",
        "dataset[\"type\"] = dataset[\"images\"].apply(lambda s:\"hd\" if \"crop_h\" in s else \"normal\")\n",
        "\n",
        "images = dataset[\"images\"]\n",
        "labels = dataset[\"labels\"]\n",
        "\n",
        "max_length = max([len(label) for label in labels])\n",
        "dataset[\"labels\"]= dataset[\"labels\"].apply(lambda s:s+(max_length-len(s))*\"#\")\n",
        "\n",
        "labels = dataset[\"labels\"]\n",
        "\n",
        "characters = set(char for label in labels for char in label)\n",
        "\n",
        "\n",
        "batch_size = 16\n",
        "\n",
        "img_width = 200\n",
        "img_height = 50\n",
        "\n",
        "downsample_factor = 4\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0_buVKUakL_"
      },
      "source": [
        "Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XEvBPFeSik9"
      },
      "source": [
        "# Mapping characters to integers\n",
        "char_to_num = layers.experimental.preprocessing.StringLookup(\n",
        "    vocabulary=list(characters), num_oov_indices=0, mask_token=None\n",
        ")\n",
        "\n",
        "# Mapping integers back to original characters\n",
        "num_to_char = layers.experimental.preprocessing.StringLookup(\n",
        "    vocabulary=char_to_num.get_vocabulary(), mask_token=None, invert=True\n",
        ")\n",
        "\n",
        "\n",
        "# Splitting data into training and validation sets\n",
        "#X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.20, random_state=42)\n",
        "#X_train, X_valid, y_train, y_valid = train_test_split( X_train,y_train ,test_size=0.10, random_state=42)\n",
        "\n",
        "def split_data(images, labels, train_size=0.8, shuffle=True):\n",
        "    # 1. Get the total size of the dataset\n",
        "    size = len(images)\n",
        "    # 2. Make an indices array and shuffle it, if required\n",
        "    indices = np.arange(size)\n",
        "    if shuffle:\n",
        "        np.random.shuffle(indices)\n",
        "    # 3. Get the size of training samples\n",
        "    train_samples = int(size * train_size)\n",
        "    # 4. Split data into training and validation sets\n",
        "    x_train, y_train = images[indices[:train_samples]], labels[indices[:train_samples]]\n",
        "    x_valid, y_valid = images[indices[train_samples:]], labels[indices[train_samples:]]\n",
        "    return x_train, x_valid, y_train, y_valid\n",
        "\n",
        "\n",
        "# Splitting data into training and validation sets\n",
        "x_train, x_valid, y_train, y_valid = split_data(np.array(images), np.array(labels))\n",
        "\n",
        "\n",
        "\n",
        "def encode_single_sample(img_path, label):\n",
        "    # 1. Read image\n",
        "    img = tf.io.read_file(img_path)\n",
        "    # 2. Decode and convert to grayscale\n",
        "    img = tf.io.decode_png(img, channels=1)\n",
        "    # 3. Convert to float32 in [0, 1] range\n",
        "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "    # 4. Resize to the desired size\n",
        "    img = tf.image.resize(img, [img_height, img_width])\n",
        "    # 5. Transpose the image because we want the time\n",
        "    # dimension to correspond to the width of the image.\n",
        "    img = tf.transpose(img, perm=[1, 0, 2])\n",
        "    # 6. Map the characters in label to numbers\n",
        "    label = char_to_num(tf.strings.unicode_split(label, input_encoding=\"UTF-8\"))\n",
        "\n",
        "\n",
        "    return {\"image\": img, \"label\": label,\"path\":img_path}"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sC29oIHa4po"
      },
      "source": [
        "Create Test Train Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WH-BCFmLav37"
      },
      "source": [
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "train_dataset = (\n",
        "  train_dataset.map(\n",
        "       encode_single_sample, num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
        "    )\n",
        "    .batch(batch_size)\n",
        "    .prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        ")\n",
        "\n",
        "validation_dataset = tf.data.Dataset.from_tensor_slices((x_valid, y_valid))\n",
        "validation_dataset = (\n",
        "    validation_dataset.map(\n",
        "        encode_single_sample, num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
        "    )\n",
        "    .batch(batch_size)\n",
        "    .prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        ")\n"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NogM0gm24OPl"
      },
      "source": [
        "Build model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rOyNJ9S2a-DI",
        "outputId": "f94573ae-ea0c-4ba8-8937-6829ac002a76"
      },
      "source": [
        "class CTCLayer(layers.Layer):\n",
        "    def __init__(self, name=None):\n",
        "        super().__init__(name=name)\n",
        "        self.loss_fn = keras.backend.ctc_batch_cost\n",
        "\n",
        "    def call(self, y_true, y_pred):\n",
        "      \n",
        "        print(tf.shape(y_true))\n",
        "        batch_len = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n",
        "        input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n",
        "        label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n",
        "\n",
        "        input_length = input_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
        "        label_length = label_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
        "\n",
        "        \n",
        "        loss = self.loss_fn(y_true, y_pred, input_length, label_length)\n",
        "        self.add_loss(loss)\n",
        "\n",
        "       \n",
        "        return y_pred\n",
        "\n",
        "\n",
        "def build_model():\n",
        "    # Inputs to the model\n",
        "    input_img = layers.Input(\n",
        "        shape=(img_width, img_height, 1), name=\"image\", dtype=\"float32\"\n",
        "    )\n",
        "    labels = layers.Input(name=\"label\", shape=(None,), dtype=\"float32\")\n",
        "\n",
        "    # First conv block\n",
        "    x = layers.Conv2D(\n",
        "        64,\n",
        "        (3, 3),\n",
        "        activation=\"relu\",\n",
        "        kernel_initializer=\"he_normal\",\n",
        "        padding=\"same\",\n",
        "        name=\"Conv1\",\n",
        "    )(input_img)\n",
        "    \n",
        "\n",
        "    # Second conv block\n",
        "    x = layers.Conv2D(\n",
        "        64,\n",
        "        (3, 3),\n",
        "        activation=\"relu\",\n",
        "        kernel_initializer=\"he_normal\",\n",
        "        padding=\"same\",\n",
        "        name=\"Conv2\",\n",
        "    )(x)\n",
        "    x = layers.MaxPooling2D((2, 2), name=\"pool1\")(x)\n",
        "\n",
        "    # Third conv block\n",
        "    x = layers.Conv2D(\n",
        "        64,\n",
        "        (3, 3),\n",
        "        activation=\"relu\",\n",
        "        kernel_initializer=\"he_normal\",\n",
        "        padding=\"same\",\n",
        "        name=\"Conv3\",\n",
        "    )(x)\n",
        "   \n",
        "\n",
        "    # Furth conv block\n",
        "    x = layers.Conv2D(\n",
        "        64,\n",
        "        (3, 3),\n",
        "        activation=\"relu\",\n",
        "        kernel_initializer=\"he_normal\",\n",
        "        padding=\"same\",\n",
        "        name=\"Conv4\",\n",
        "    )(x)\n",
        "\n",
        "    x = layers.MaxPooling2D((2, 2), name=\"pool2\")(x)\n",
        "    # Batch normalization layer\n",
        "    batch_norm_4 = layers.BatchNormalization()\n",
        "    \n",
        "    x = layers.Conv2D(\n",
        "        64,\n",
        "        (3, 3),\n",
        "        activation=\"relu\",\n",
        "        kernel_initializer=\"he_normal\",\n",
        "        padding=\"same\",\n",
        "        name=\"Conv5\",\n",
        "    )(x)\n",
        "\n",
        "    x = layers.Conv2D(\n",
        "        64,\n",
        "        (3, 3),\n",
        "        activation=\"relu\",\n",
        "        kernel_initializer=\"he_normal\",\n",
        "        padding=\"same\",\n",
        "        name=\"Conv6\",\n",
        "    )(x)\n",
        "    x = layers.MaxPooling2D((2, 2), name=\"pool3\")(x)\n",
        "    \n",
        "    x = layers.Conv2D(\n",
        "        64,\n",
        "        (3, 3),\n",
        "        activation=\"relu\",\n",
        "        kernel_initializer=\"he_normal\",\n",
        "        padding=\"same\",\n",
        "        name=\"Conv7\",\n",
        "    )(x)\n",
        "    \n",
        "\n",
        "    x = layers.MaxPooling2D((2, 2), name=\"pool4\")(x)\n",
        "\n",
        "    # Batch normalization layer\n",
        "    batch_norm_5 = layers.BatchNormalization()\n",
        "    # We have used four max pool with pool size and strides 2.\n",
        "    # Hence, downsampled feature maps are 16x smaller. The number of\n",
        "    # filters in the last layer is 64. Reshape accordingly before\n",
        "    # passing the output to the RNN part of the model\n",
        "    new_shape = ((img_width // 16), (img_height // 16) * 64)\n",
        "    x = layers.Reshape(target_shape=new_shape, name=\"reshape\")(x)\n",
        "    x = layers.Dense(64, activation=\"relu\", name=\"dense1\")(x)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "\n",
        "    # RNNs\n",
        "    x = layers.Bidirectional(layers.LSTM(128, return_sequences=True, dropout=0.25))(x)\n",
        "    x = layers.Bidirectional(layers.LSTM(128, return_sequences=True, dropout=0.25))(x)\n",
        "\n",
        "    # Output layer\n",
        "    x = layers.Dense(len(characters) + 1, activation=\"softmax\", name=\"dense2\")(x)\n",
        "\n",
        "    # Add CTC layer for calculating CTC loss at each step\n",
        "    output = CTCLayer(name=\"ctc_loss\")(labels, x)\n",
        "\n",
        "    # Define the model\n",
        "    model = keras.models.Model(\n",
        "        inputs=[input_img, labels], outputs=output, name=\"ocr_model_v1\"\n",
        "    )\n",
        "    # Optimizer\n",
        "    opt = keras.optimizers.Adam()\n",
        "    # Compile the model and return\n",
        "    model.compile(optimizer=opt)\n",
        "    return model\n",
        "\n",
        "\n",
        "# Get the model\n",
        "model = build_model()\n",
        "model.summary()"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"ctc_loss/Shape:0\", shape=(2,), dtype=int32)\n",
            "Model: \"ocr_model_v1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "image (InputLayer)              [(None, 200, 50, 1)] 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Conv1 (Conv2D)                  (None, 200, 50, 64)  640         image[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "Conv2 (Conv2D)                  (None, 200, 50, 64)  36928       Conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "pool1 (MaxPooling2D)            (None, 100, 25, 64)  0           Conv2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "Conv3 (Conv2D)                  (None, 100, 25, 64)  36928       pool1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "Conv4 (Conv2D)                  (None, 100, 25, 64)  36928       Conv3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "pool2 (MaxPooling2D)            (None, 50, 12, 64)   0           Conv4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "Conv5 (Conv2D)                  (None, 50, 12, 64)   36928       pool2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "Conv6 (Conv2D)                  (None, 50, 12, 64)   36928       Conv5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "pool3 (MaxPooling2D)            (None, 25, 6, 64)    0           Conv6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "Conv7 (Conv2D)                  (None, 25, 6, 64)    36928       pool3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "pool4 (MaxPooling2D)            (None, 12, 3, 64)    0           Conv7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "reshape (Reshape)               (None, 12, 192)      0           pool4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense1 (Dense)                  (None, 12, 64)       12352       reshape[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 12, 64)       0           dense1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_6 (Bidirectional) (None, 12, 256)      197632      dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_7 (Bidirectional) (None, 12, 256)      394240      bidirectional_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "label (InputLayer)              [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense2 (Dense)                  (None, 12, 33)       8481        bidirectional_7[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "ctc_loss (CTCLayer)             (None, 12, 33)       0           label[0][0]                      \n",
            "                                                                 dense2[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 834,913\n",
            "Trainable params: 834,913\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDLLUJGn4TJi"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukbua47yN045",
        "outputId": "1f4ca47d-5237-4b70-a598-aef01f8a3c4d"
      },
      "source": [
        "epochs = 100\n",
        "early_stopping_patience = 10\n",
        "# Add early stopping\n",
        "early_stopping = keras.callbacks.EarlyStopping(\n",
        "    monitor=\"val_loss\", patience=early_stopping_patience, restore_best_weights=True\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=validation_dataset,\n",
        "    epochs=epochs,\n",
        "    callbacks=[early_stopping],\n",
        ")"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py:595: UserWarning: Input dict contained keys ['path'] which did not match any model input. They will be ignored by the model.\n",
            "  [n for n in tensors.keys() if n not in ref_input_names])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"ocr_model_v1/ctc_loss/Shape:0\", shape=(2,), dtype=int32)\n",
            "Tensor(\"ocr_model_v1/ctc_loss/Shape:0\", shape=(2,), dtype=int32)\n",
            "32/33 [============================>.] - ETA: 0s - loss: 23.8175Tensor(\"ocr_model_v1/ctc_loss/Shape:0\", shape=(2,), dtype=int32)\n",
            "33/33 [==============================] - 9s 138ms/step - loss: 23.6590 - val_loss: 19.1254\n",
            "Epoch 2/100\n",
            "33/33 [==============================] - 3s 92ms/step - loss: 18.9885 - val_loss: 18.7110\n",
            "Epoch 3/100\n",
            "33/33 [==============================] - 3s 93ms/step - loss: 18.5490 - val_loss: 18.4132\n",
            "Epoch 4/100\n",
            "33/33 [==============================] - 3s 93ms/step - loss: 18.2575 - val_loss: 18.1215\n",
            "Epoch 5/100\n",
            "33/33 [==============================] - 3s 97ms/step - loss: 17.9803 - val_loss: 17.8260\n",
            "Epoch 6/100\n",
            "33/33 [==============================] - 3s 91ms/step - loss: 17.6935 - val_loss: 17.6160\n",
            "Epoch 7/100\n",
            "33/33 [==============================] - 3s 93ms/step - loss: 17.4749 - val_loss: 17.5109\n",
            "Epoch 8/100\n",
            "33/33 [==============================] - 3s 94ms/step - loss: 17.3843 - val_loss: 17.4620\n",
            "Epoch 9/100\n",
            "33/33 [==============================] - 3s 94ms/step - loss: 17.3400 - val_loss: 17.4479\n",
            "Epoch 10/100\n",
            "33/33 [==============================] - 3s 95ms/step - loss: 17.3171 - val_loss: 17.4545\n",
            "Epoch 11/100\n",
            "33/33 [==============================] - 3s 95ms/step - loss: 17.2700 - val_loss: 17.4118\n",
            "Epoch 12/100\n",
            "33/33 [==============================] - 3s 93ms/step - loss: 17.2045 - val_loss: 17.3014\n",
            "Epoch 13/100\n",
            "33/33 [==============================] - 3s 94ms/step - loss: 17.0094 - val_loss: 16.7855\n",
            "Epoch 14/100\n",
            "33/33 [==============================] - 3s 93ms/step - loss: 16.4411 - val_loss: 16.2080\n",
            "Epoch 15/100\n",
            "33/33 [==============================] - 3s 92ms/step - loss: 15.6924 - val_loss: 14.6606\n",
            "Epoch 16/100\n",
            "33/33 [==============================] - 3s 93ms/step - loss: 14.2010 - val_loss: 12.5018\n",
            "Epoch 17/100\n",
            "33/33 [==============================] - 3s 93ms/step - loss: 12.1601 - val_loss: 10.4773\n",
            "Epoch 18/100\n",
            "33/33 [==============================] - 3s 91ms/step - loss: 10.2520 - val_loss: 9.5882\n",
            "Epoch 19/100\n",
            "33/33 [==============================] - 3s 94ms/step - loss: 9.1138 - val_loss: 7.8056\n",
            "Epoch 20/100\n",
            "33/33 [==============================] - 3s 94ms/step - loss: 7.5746 - val_loss: 7.0012\n",
            "Epoch 21/100\n",
            "33/33 [==============================] - 3s 94ms/step - loss: 6.4412 - val_loss: 5.9327\n",
            "Epoch 22/100\n",
            "33/33 [==============================] - 3s 95ms/step - loss: 5.5989 - val_loss: 5.1757\n",
            "Epoch 23/100\n",
            "33/33 [==============================] - 3s 93ms/step - loss: 4.6465 - val_loss: 4.7952\n",
            "Epoch 24/100\n",
            "33/33 [==============================] - 3s 92ms/step - loss: 3.8815 - val_loss: 4.7324\n",
            "Epoch 25/100\n",
            "33/33 [==============================] - 3s 94ms/step - loss: 3.5782 - val_loss: 4.3784\n",
            "Epoch 26/100\n",
            "33/33 [==============================] - 3s 91ms/step - loss: 3.2766 - val_loss: 4.1520\n",
            "Epoch 27/100\n",
            "33/33 [==============================] - 3s 91ms/step - loss: 2.8388 - val_loss: 3.8540\n",
            "Epoch 28/100\n",
            "33/33 [==============================] - 3s 91ms/step - loss: 2.5265 - val_loss: 3.9411\n",
            "Epoch 29/100\n",
            "33/33 [==============================] - 3s 92ms/step - loss: 2.2137 - val_loss: 3.8710\n",
            "Epoch 30/100\n",
            "33/33 [==============================] - 3s 95ms/step - loss: 2.1195 - val_loss: 3.4681\n",
            "Epoch 31/100\n",
            "33/33 [==============================] - 3s 93ms/step - loss: 1.7503 - val_loss: 3.7046\n",
            "Epoch 32/100\n",
            "33/33 [==============================] - 3s 92ms/step - loss: 1.7034 - val_loss: 3.1691\n",
            "Epoch 33/100\n",
            "33/33 [==============================] - 3s 95ms/step - loss: 1.5551 - val_loss: 3.1746\n",
            "Epoch 34/100\n",
            "33/33 [==============================] - 3s 94ms/step - loss: 1.4006 - val_loss: 2.8713\n",
            "Epoch 35/100\n",
            "33/33 [==============================] - 3s 93ms/step - loss: 1.1860 - val_loss: 2.6488\n",
            "Epoch 36/100\n",
            "33/33 [==============================] - 3s 89ms/step - loss: 1.0241 - val_loss: 2.4764\n",
            "Epoch 37/100\n",
            "33/33 [==============================] - 3s 93ms/step - loss: 0.8806 - val_loss: 2.4817\n",
            "Epoch 38/100\n",
            "33/33 [==============================] - 3s 92ms/step - loss: 0.8142 - val_loss: 2.7481\n",
            "Epoch 39/100\n",
            "33/33 [==============================] - 3s 92ms/step - loss: 0.8939 - val_loss: 2.4917\n",
            "Epoch 40/100\n",
            "33/33 [==============================] - 3s 95ms/step - loss: 0.8426 - val_loss: 2.6993\n",
            "Epoch 41/100\n",
            "33/33 [==============================] - 3s 94ms/step - loss: 0.7078 - val_loss: 2.3828\n",
            "Epoch 42/100\n",
            "33/33 [==============================] - 3s 93ms/step - loss: 0.7201 - val_loss: 2.4856\n",
            "Epoch 43/100\n",
            "33/33 [==============================] - 3s 91ms/step - loss: 0.6568 - val_loss: 2.4853\n",
            "Epoch 44/100\n",
            "33/33 [==============================] - 3s 95ms/step - loss: 0.6188 - val_loss: 2.2816\n",
            "Epoch 45/100\n",
            "33/33 [==============================] - 3s 94ms/step - loss: 0.5460 - val_loss: 2.1463\n",
            "Epoch 46/100\n",
            "33/33 [==============================] - 3s 95ms/step - loss: 0.4645 - val_loss: 2.2374\n",
            "Epoch 47/100\n",
            "33/33 [==============================] - 3s 93ms/step - loss: 0.4399 - val_loss: 2.1368\n",
            "Epoch 48/100\n",
            "33/33 [==============================] - 3s 94ms/step - loss: 0.4600 - val_loss: 2.1732\n",
            "Epoch 49/100\n",
            "33/33 [==============================] - 3s 95ms/step - loss: 0.4262 - val_loss: 2.3900\n",
            "Epoch 50/100\n",
            "33/33 [==============================] - 3s 93ms/step - loss: 0.4314 - val_loss: 2.0081\n",
            "Epoch 51/100\n",
            "33/33 [==============================] - 3s 90ms/step - loss: 0.3244 - val_loss: 2.0257\n",
            "Epoch 52/100\n",
            "33/33 [==============================] - 3s 94ms/step - loss: 0.3330 - val_loss: 1.8848\n",
            "Epoch 53/100\n",
            "33/33 [==============================] - 3s 96ms/step - loss: 0.2750 - val_loss: 1.8187\n",
            "Epoch 54/100\n",
            "33/33 [==============================] - 3s 93ms/step - loss: 0.2613 - val_loss: 1.9196\n",
            "Epoch 55/100\n",
            "33/33 [==============================] - 3s 90ms/step - loss: 0.2505 - val_loss: 2.0792\n",
            "Epoch 56/100\n",
            "33/33 [==============================] - 3s 96ms/step - loss: 0.1904 - val_loss: 2.0474\n",
            "Epoch 57/100\n",
            "33/33 [==============================] - 3s 91ms/step - loss: 0.2125 - val_loss: 1.9276\n",
            "Epoch 58/100\n",
            "33/33 [==============================] - 3s 97ms/step - loss: 0.2457 - val_loss: 1.9807\n",
            "Epoch 59/100\n",
            "33/33 [==============================] - 3s 99ms/step - loss: 0.2132 - val_loss: 1.9285\n",
            "Epoch 60/100\n",
            "33/33 [==============================] - 3s 93ms/step - loss: 0.1496 - val_loss: 2.0039\n",
            "Epoch 61/100\n",
            "33/33 [==============================] - 3s 92ms/step - loss: 0.1717 - val_loss: 2.0290\n",
            "Epoch 62/100\n",
            "33/33 [==============================] - 3s 93ms/step - loss: 0.1704 - val_loss: 2.0497\n",
            "Epoch 63/100\n",
            "33/33 [==============================] - 3s 93ms/step - loss: 0.1414 - val_loss: 1.9229\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIlPqrtI4Wcj"
      },
      "source": [
        "Predictions on validation data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4cStXDTTPh7j",
        "outputId": "c5cac290-7246-4f40-b226-ecfb7cc994c4"
      },
      "source": [
        "# Get the prediction model by extracting layers till the output layer\n",
        "prediction_model = keras.models.Model(\n",
        "    model.get_layer(name=\"image\").input, model.get_layer(name=\"dense2\").output\n",
        ")\n",
        "\n",
        "\n",
        "prediction_model.summary()\n",
        "\n",
        "# A utility function to decode the output of the network\n",
        "def decode_batch_predictions(pred):\n",
        "    input_len = np.ones(pred.shape[0]) * pred.shape[1]\n",
        "    # Use greedy search. For complex tasks, you can use beam search\n",
        "    results = keras.backend.ctc_decode(pred, input_length=input_len, greedy=True)[0][0][\n",
        "        :, :max_length\n",
        "    ]\n",
        "    # Iterate over the results and get back the text\n",
        "    output_text = []\n",
        "    for res in results:\n",
        "        res = tf.strings.reduce_join(num_to_char(res)).numpy().decode(\"utf-8\")\n",
        "        output_text.append(res)\n",
        "    return output_text\n",
        "\n",
        "predictions = []\n",
        "orig_texts = []\n",
        "image_paths = []\n",
        "\n",
        "for batch in validation_dataset:\n",
        "    batch_images = batch[\"image\"]\n",
        "    batch_labels = batch[\"label\"]\n",
        "    batch_paths = batch[\"path\"]\n",
        " \n",
        "    preds = prediction_model.predict(batch_images)\n",
        "    pred_texts = decode_batch_predictions(preds)\n",
        "    predictions = predictions + pred_texts\n",
        "\n",
        "    \n",
        "    for label in batch_labels:\n",
        "        label = tf.strings.reduce_join(num_to_char(label)).numpy().decode(\"utf-8\")\n",
        "        orig_texts.append(label)\n",
        "  \n",
        "    for path in batch_paths:\n",
        "      image_paths.append(tf.strings.reduce_join(path).numpy().decode(\"utf-8\"))"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "image (InputLayer)           [(None, 200, 50, 1)]      0         \n",
            "_________________________________________________________________\n",
            "Conv1 (Conv2D)               (None, 200, 50, 64)       640       \n",
            "_________________________________________________________________\n",
            "Conv2 (Conv2D)               (None, 200, 50, 64)       36928     \n",
            "_________________________________________________________________\n",
            "pool1 (MaxPooling2D)         (None, 100, 25, 64)       0         \n",
            "_________________________________________________________________\n",
            "Conv3 (Conv2D)               (None, 100, 25, 64)       36928     \n",
            "_________________________________________________________________\n",
            "Conv4 (Conv2D)               (None, 100, 25, 64)       36928     \n",
            "_________________________________________________________________\n",
            "pool2 (MaxPooling2D)         (None, 50, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "Conv5 (Conv2D)               (None, 50, 12, 64)        36928     \n",
            "_________________________________________________________________\n",
            "Conv6 (Conv2D)               (None, 50, 12, 64)        36928     \n",
            "_________________________________________________________________\n",
            "pool3 (MaxPooling2D)         (None, 25, 6, 64)         0         \n",
            "_________________________________________________________________\n",
            "Conv7 (Conv2D)               (None, 25, 6, 64)         36928     \n",
            "_________________________________________________________________\n",
            "pool4 (MaxPooling2D)         (None, 12, 3, 64)         0         \n",
            "_________________________________________________________________\n",
            "reshape (Reshape)            (None, 12, 192)           0         \n",
            "_________________________________________________________________\n",
            "dense1 (Dense)               (None, 12, 64)            12352     \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 12, 64)            0         \n",
            "_________________________________________________________________\n",
            "bidirectional_6 (Bidirection (None, 12, 256)           197632    \n",
            "_________________________________________________________________\n",
            "bidirectional_7 (Bidirection (None, 12, 256)           394240    \n",
            "_________________________________________________________________\n",
            "dense2 (Dense)               (None, 12, 33)            8481      \n",
            "=================================================================\n",
            "Total params: 834,913\n",
            "Trainable params: 834,913\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1X2jb-9m4chT"
      },
      "source": [
        "Save model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIR-R2jKIaRk"
      },
      "source": [
        "prediction_model.save(\"7cnn_128lstm_model.h5\")"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CB5W57mK4e42"
      },
      "source": [
        "Measure accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SaukXVtRP0Za"
      },
      "source": [
        "output_df = pd.DataFrame()\n",
        "output_df[\"predicted_text\"] = predictions\n",
        "output_df[\"original_text\"] = orig_texts\n",
        "output_df[\"img_paths\"] = image_paths\n",
        "output_df[\"predicted_text\"]=output_df[\"predicted_text\"].apply(lambda s:s.replace(\"[UNK]\",\"\"))\n",
        "output_df[\"original_text\"]=output_df[\"original_text\"].apply(lambda s:s.replace(\"[UNK]\",\"\"))\n",
        "output_df.to_csv(\"output.csv\")"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWqowsXvjrdQ",
        "outputId": "75f366e6-f3b2-4b92-a5cc-9dd7a73c1d76"
      },
      "source": [
        "pd.DataFrame(output_df[\"predicted_text\"]==output_df[\"original_text\"]).value_counts()"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True     109\n",
              "False     22\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "ljcf6HKMUMG6",
        "outputId": "6c16f179-cb66-42dc-dbea-9fccba42a721"
      },
      "source": [
        "output_df"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>predicted_text</th>\n",
              "      <th>original_text</th>\n",
              "      <th>img_paths</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5B82908</td>\n",
              "      <td>5B82908</td>\n",
              "      <td>hdr/crop_h2/I00077.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2Z5672</td>\n",
              "      <td>5M56740</td>\n",
              "      <td>normal/crop_m4/I00027.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5B1149</td>\n",
              "      <td>5B11149</td>\n",
              "      <td>normal/crop_m2/I00067.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7B11607</td>\n",
              "      <td>7B11607</td>\n",
              "      <td>hdr/crop_h3/I00040.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7B29430</td>\n",
              "      <td>7B29430</td>\n",
              "      <td>normal/crop_m2/I00043.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>126</th>\n",
              "      <td>7B58307</td>\n",
              "      <td>7B58307</td>\n",
              "      <td>normal/crop_m2/I00052.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127</th>\n",
              "      <td>8B71401</td>\n",
              "      <td>8B71401</td>\n",
              "      <td>normal/crop_m2/I00020.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128</th>\n",
              "      <td>8B86266</td>\n",
              "      <td>8B86266</td>\n",
              "      <td>hdr/crop_h3/I00110.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>129</th>\n",
              "      <td>9B78701</td>\n",
              "      <td>9B78701</td>\n",
              "      <td>hdr/crop_h4/I00053.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>130</th>\n",
              "      <td>7B14156</td>\n",
              "      <td>7B14156</td>\n",
              "      <td>hdr/crop_h4/I00026.png</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>131 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    predicted_text original_text                  img_paths\n",
              "0          5B82908       5B82908     hdr/crop_h2/I00077.png\n",
              "1           2Z5672       5M56740  normal/crop_m4/I00027.png\n",
              "2           5B1149       5B11149  normal/crop_m2/I00067.png\n",
              "3          7B11607       7B11607     hdr/crop_h3/I00040.png\n",
              "4          7B29430       7B29430  normal/crop_m2/I00043.png\n",
              "..             ...           ...                        ...\n",
              "126        7B58307       7B58307  normal/crop_m2/I00052.png\n",
              "127        8B71401       8B71401  normal/crop_m2/I00020.png\n",
              "128        8B86266       8B86266     hdr/crop_h3/I00110.png\n",
              "129        9B78701       9B78701     hdr/crop_h4/I00053.png\n",
              "130        7B14156       7B14156     hdr/crop_h4/I00026.png\n",
              "\n",
              "[131 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    }
  ]
}